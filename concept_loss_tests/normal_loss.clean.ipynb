{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling from independent normals using parameterization trick\n",
    "def sample(num_concepts, num_latent_concepts, batch_size):\n",
    "    mu_hat = np.random.random(num_concepts).reshape(num_concepts, 1)*2 # (n_concepts,  1)\n",
    "    true_sigma_hat = np.random.random(num_concepts).reshape(num_concepts, 1)*5 # (n_concepts,  1)\n",
    "    c_hat = np.random.standard_normal(batch_size*num_concepts).reshape(batch_size, num_concepts, 1) * true_sigma_hat**0.5 + mu_hat # (batch_size, n_concepts,  1)\n",
    "\n",
    "    mu_tilde = np.random.random(num_latent_concepts).reshape(num_latent_concepts, 1)*5 # (n_latent,  1)\n",
    "    true_sigma_tilde = np.random.random(num_latent_concepts).reshape(num_latent_concepts, 1)*10 # (n_latent,  1)\n",
    "    c_tilde = np.random.standard_normal(batch_size*num_latent_concepts).reshape(batch_size, num_latent_concepts, 1) * true_sigma_tilde**0.5 + mu_tilde # (batch_size, n_latent,  1)\n",
    "    # print(list(true_sigma_hat.squeeze())+list(true_sigma_tilde.squeeze()))\n",
    "    return c_hat, c_tilde\n",
    "\n",
    "# c_hat_mean = np.mean(c_hat, axis=0) # (n_concepts, 1)\n",
    "# c_tilde_mean = np.mean(c_tilde, axis=0) # (n_latent, 1)\n",
    "# print(c_hat.shape, c_tilde.shape)\n",
    "\n",
    "# sampling from independent normals using parameterization trick\n",
    "def sample_c(num_concepts, batch_size):\n",
    "    mu_hat = np.random.random(num_concepts).reshape(num_concepts)*2 # (n_concepts,  1)\n",
    "    true_sigma_hat = np.random.random(num_concepts*num_concepts).reshape(num_concepts, num_concepts)\n",
    "    true_sigma_hat = np.matmul(true_sigma_hat, true_sigma_hat.T)*5 # (n_concepts,  1)\n",
    "    c_hat = np.random.multivariate_normal(mu_hat, true_sigma_hat, batch_size)\n",
    "    return c_hat, mu_hat, true_sigma_hat\n",
    "\n",
    "# c_hat_mean = np.mean(c_hat, axis=0) # (n_concepts, 1)\n",
    "# c_tilde_mean = np.mean(c_tilde, axis=0) # (n_latent, 1)\n",
    "# print(c_hat.shape, c_tilde.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_to_std(batch_size, std=1, mean=0, samples=100):\n",
    "    min_corr = -1\n",
    "    max_corr = 1\n",
    "    step = 0.01\n",
    "    scale_log = 2\n",
    "    scale = 10**scale_log\n",
    "    corr_to_std = {}\n",
    "\n",
    "    for corr in range(int(scale*min_corr), int((max_corr+step)*scale), int(step*scale)):\n",
    "        corr /= scale\n",
    "        cov_matrix = np.ones((2,2))\n",
    "        np.fill_diagonal(cov_matrix, std**2)\n",
    "        cov_matrix[0,1] = corr*std**2\n",
    "        cov_matrix[1,0] = corr*std**2\n",
    "        z = np.random.multivariate_normal(np.ones(2)*mean, cov_matrix, (samples, batch_size))\n",
    "        corr_z = []\n",
    "        for sample in z:\n",
    "            corr_z.append(np.corrcoef(sample, rowvar=False)[0,1])\n",
    "        std_corr_z = np.std(corr_z)\n",
    "        corr_to_std[int(corr*scale)] = std_corr_z\n",
    "\n",
    "        def get_std(correlation): # interpolation\n",
    "            return corr_to_std[int(round(correlation, scale_log)*scale)]\n",
    "            # if correlation == 1:\n",
    "            #     return corr_to_std[correlation]\n",
    "            # if correlation < step:\n",
    "            #     return corr_to_std[0]*correlation*100 + corr_to_std[int(step*scale)]*(1-correlation*100)\n",
    "            # corr_truncate = int(correlation * scale) / scale\n",
    "            # alpha = int(correlation*scale*100) % int(corr_truncate*scale*100) / 100 # 0.1234 -> 0.34   (1234%1200)\n",
    "            # return corr_to_std[int(corr_truncate*scale)]*alpha + corr_to_std[int((corr_truncate+step)*scale)]*(1-alpha)\n",
    "    return get_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov(c, get_std, delta=1):\n",
    "    p_hat = np.corrcoef(c, rowvar=False) # 256+128, 256+128\n",
    "\n",
    "    # calculate S_p\n",
    "    start = time.time()\n",
    "    S_p = np.sum(get_std(p_hat)**2)**0.5\n",
    "    print('time to convert:', time.time()-start)\n",
    "\n",
    "    # estimate gamma\n",
    "    for gamma in range(2, 10, 2):\n",
    "        p_hat_gamma = p_hat**gamma * p_hat\n",
    "        # print('gamma:', gamma, np.linalg.norm(p_hat - p_hat_gamma), delta * S_p)\n",
    "        if np.linalg.norm(p_hat - p_hat_gamma) >= delta * S_p:\n",
    "            gamma_star = gamma\n",
    "            break\n",
    "\n",
    "    # estimate alpha\n",
    "    scale = 1000\n",
    "    step = 0.1\n",
    "    for alpha in range(0, int((1+step)*scale), int(step*scale)):\n",
    "        alpha /= scale\n",
    "        L_alpha = alpha * p_hat ** gamma_star + (1-alpha) *p_hat ** (gamma_star-2)\n",
    "        p_hat_alpha = L_alpha * p_hat\n",
    "        # print('alpha:', alpha, np.linalg.norm(p_hat - p_hat_alpha), delta * S_p)\n",
    "        if np.linalg.norm(p_hat - p_hat_alpha) >= delta * S_p:\n",
    "            alpha_star = alpha - step\n",
    "            break\n",
    "\n",
    "    L_alpha_star = alpha_star * p_hat ** gamma_star + (1-alpha_star) *p_hat ** (gamma_star-2)\n",
    "    p_hat_nice = L_alpha_star * p_hat\n",
    "\n",
    "    V_hat = np.diagflat(np.std(c, axis=0))\n",
    "    P_hat_nice = np.matmul(np.matmul(V_hat, p_hat_nice), V_hat) # Covariance estimate\n",
    "    return P_hat_nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1719956398010254\n",
      "262.90954629192595 627.5653749313013 364.6559352434739\n",
      "235.4340234613548 627.5653749313013 392.1318918107918\n",
      "SlogdetResult(sign=1.0, logabsdet=2182.2799581685376)\n",
      "SlogdetResult(sign=1.0, logabsdet=1605.6184721785673)\n",
      "SlogdetResult(sign=-1.0, logabsdet=-11220.156101056447)\n"
     ]
    }
   ],
   "source": [
    "num_concepts = 500\n",
    "batch_size = 64\n",
    "c_hat, mu_hat, true_sigma_hat = sample_c(num_concepts, batch_size)\n",
    "get_std = np.vectorize(get_corr_to_std(batch_size))\n",
    "\n",
    "\n",
    "sigma_hat = get_cov(c_hat, get_std)\n",
    "np_sigma = np.cov(c_hat, rowvar=False)\n",
    "\n",
    "print(np.mean(np.absolute(true_sigma_hat-sigma_hat)), np.mean(np.absolute(true_sigma_hat)), np.mean(np.absolute(sigma_hat)))\n",
    "print(np.mean(np.absolute(true_sigma_hat-np_sigma)), np.mean(np.absolute(true_sigma_hat)), np.mean(np.absolute(np_sigma)))\n",
    "\n",
    "print(np.linalg.slogdet(true_sigma_hat))\n",
    "print(np.linalg.slogdet(sigma_hat))\n",
    "print(np.linalg.slogdet(np_sigma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_to_std_torch(batch_size, std=1, mean=0, samples=100):\n",
    "    min_corr = -1\n",
    "    max_corr = 1\n",
    "    step = 0.01\n",
    "    scale_log = 2\n",
    "    scale = 10**scale_log\n",
    "    corr_to_std = []\n",
    "    remapping_index = torch.arange(int(scale*min_corr), int((max_corr+step)*scale), int(step*scale))\n",
    "\n",
    "    for corr in range(int(scale*min_corr), int((max_corr+step)*scale), int(step*scale)):\n",
    "        corr /= scale\n",
    "        cov_matrix = np.ones((2,2))\n",
    "        np.fill_diagonal(cov_matrix, std**2)\n",
    "        cov_matrix[0,1] = corr*std**2\n",
    "        cov_matrix[1,0] = corr*std**2\n",
    "        z = np.random.multivariate_normal(np.ones(2)*mean, cov_matrix, (samples, batch_size))\n",
    "        corr_z = []\n",
    "        for sample in z:\n",
    "            corr_z.append(np.corrcoef(sample, rowvar=False)[0,1])\n",
    "        std_corr_z = np.std(corr_z)\n",
    "        corr_to_std.append(std_corr_z)\n",
    "        \n",
    "    corr_to_std = torch.tensor(corr_to_std)\n",
    "\n",
    "    def get_std(correlation): # interpolation\n",
    "        index = torch.round(correlation*scale)\n",
    "        bucket_index = torch.bucketize(index.ravel(), remapping_index)\n",
    "        return corr_to_std[bucket_index].reshape(bucket_index.shape)\n",
    "    return get_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_torch(c, get_std, delta=1):\n",
    "    p_hat = torch.corrcoef(c.T) # 256+128, 256+128\n",
    "\n",
    "    # calculate S_p\n",
    "    # start = time.time()\n",
    "    # p_hat.cpu().detach().numpy()\n",
    "    # print('time to detach', time.time()-start)\n",
    "    start = time.time()\n",
    "    S_p = torch.sum(get_std(p_hat)**2)**0.5\n",
    "    print('time to convert:', time.time()-start)\n",
    "\n",
    "\n",
    "    # estimate gamma\n",
    "    for gamma in range(2, 10, 2):\n",
    "        p_hat_gamma = p_hat**gamma * p_hat\n",
    "        # print('gamma:', gamma, torch.linalg.norm(p_hat - p_hat_gamma), delta * S_p)\n",
    "        if torch.linalg.norm(p_hat - p_hat_gamma) >= delta * S_p:\n",
    "            gamma_star = gamma\n",
    "            break\n",
    "\n",
    "    # estimate alpha\n",
    "    scale = 1000\n",
    "    step = 0.1\n",
    "    for alpha in range(0, int((1+step)*scale), int(step*scale)):\n",
    "        alpha /= scale\n",
    "        L_alpha = alpha * p_hat ** gamma_star + (1-alpha) *p_hat ** (gamma_star-2)\n",
    "        p_hat_alpha = L_alpha * p_hat\n",
    "        # print('alpha:', alpha, torch.linalg.norm(p_hat - p_hat_alpha), delta * S_p)\n",
    "        if torch.linalg.norm(p_hat - p_hat_alpha) >= delta * S_p:\n",
    "            alpha_star = alpha - step\n",
    "            break\n",
    "\n",
    "    L_alpha_star = alpha_star * p_hat ** gamma_star + (1-alpha_star) *p_hat ** (gamma_star-2)\n",
    "    p_hat_nice = L_alpha_star * p_hat\n",
    "\n",
    "    V_hat = torch.diagflat(torch.std(c, axis=0))\n",
    "    P_hat_nice = torch.matmul(torch.matmul(V_hat, p_hat_nice), V_hat) # Covariance estimate\n",
    "    return P_hat_nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to convert: 0.001825571060180664\n",
      "tensor(55.6570, dtype=torch.float64) tensor(625.3569, dtype=torch.float64) tensor(632.4664, dtype=torch.float64)\n",
      "tensor(61.7789, dtype=torch.float64) tensor(625.3569, dtype=torch.float64) tensor(659.7617, dtype=torch.float64)\n",
      "tensor(2173.3009, dtype=torch.float64)\n",
      "tensor(1500.5106, dtype=torch.float64)\n",
      "tensor(nan, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "num_concepts = 500\n",
    "batch_size = 64\n",
    "c_hat, mu_hat, true_sigma_hat = sample_c(num_concepts, batch_size)\n",
    "true_sigma_hat = torch.tensor(true_sigma_hat)\n",
    "c_hat = torch.tensor(c_hat)\n",
    "get_std = get_corr_to_std_torch(batch_size)\n",
    "\n",
    "\n",
    "sigma_hat = get_cov_torch(c_hat, get_std)\n",
    "torch_sigma = torch.cov(c_hat.T)\n",
    "\n",
    "print(torch.mean(torch.absolute(true_sigma_hat-sigma_hat)), torch.mean(torch.absolute(true_sigma_hat)), torch.mean(torch.absolute(sigma_hat)))\n",
    "print(torch.mean(torch.absolute(true_sigma_hat-torch_sigma)), torch.mean(torch.absolute(true_sigma_hat)), torch.mean(torch.absolute(torch_sigma)))\n",
    "\n",
    "print(torch.logdet(true_sigma_hat))\n",
    "print(torch.logdet(sigma_hat))\n",
    "print(torch.logdet(torch_sigma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017764568328857422\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "torch_sigma = torch.cov(c_hat.T)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
